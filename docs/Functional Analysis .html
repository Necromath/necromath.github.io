<!doctype html>
<html>
<head>
  <meta name="robots" content="noindex">
  <meta charset="utf-8"/>
  <title>Functional Analysis </title>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <link rel="stylesheet" type="text/css" href="style.css" />
  <script type="text/x-mathjax-config">
      MathJax.Hub.Config({ TeX: {
      extensions: ["autobold.js",
        "AMSmath.js",
        "AMSsymbols.js",
        "AMScd.js",
        "color.js"]
      Macros: {
        R: "\mathbb{R}",
        P: "\mathbb{P}",
        Norm: ["\left\|| #1 \right||",1]
      }
    }});
  </script>
  <script>
  MathJax = {
    tex: {
      inlineMath: [['$', '$'], ['\\(', '\\)']]
    },
    svg: {
      fontCache: 'global'
    }
  };
  </script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex&#45;svg.js">
  </script>


</head>
<body>
  <a href="index.html">Index</a>

  <div class="content">
    
<p>
Here are my written solutions to Chapter 5 of Folland:
</p>

<div id="[[Functional Analysis Notes]]"><h1 id="[[Functional Analysis Notes]]" class="header"><a href="#[[Functional Analysis Notes]]"><a href="Functional Analysis Notes.html">Functional Analysis Notes</a></a></h1></div>

<p>
Exercise 1: If \(X\) is a normed vector space over \(K (= \mathbb{R} \textrm{or} \mathbb{C} )\), then addition and multiplication are continuous from \(X \times X\) and \(K \times X\) to \(X\). Moreover, the norm is continuous from \(X\) to \([0,\infty)\); in fact, \(\|x\|-\|y\| \leq \|x-y\|\). 
</p>

<p>
Proof:
To prove continuity of addition we use a \(\delta - \epsilon \) proof. Let \(x,x_0,y,y_0 \in X\) be such that \(\|(x,y)-(x_0,y_0)\|=\|((x-x_0,y-y_0))\| &lt; \delta = \frac{\epsilon}{2}.\) From the definition of product norm, this is simply \(\textrm{max}(\|(x-x_0)\|,\|(y-y_0)\|).\) Then we see that under the map \(+:X\times X \rightarrow X\) we have that 
</p>

<p>
\( \begin{equation} \begin{split}  \|(x+y)-(x_0+y_0)\| &amp;= \|(x-x_0) + (y-y_0)\| \\ &amp;\leq \|x-x_0\| + \|y-y_0\| \\  &amp;&lt; \frac{\epsilon}{2} + \frac{\epsilon}{2} \\ &amp;= \epsilon \end{split}\end{equation}\) 
</p>

<p>
Thus, addition is continuous in \(X\). 
</p>

<p>
Next we prove continuity of multiplication. Let \(\lambda\) be an element of our field \(K\) and let \(x\) be an element of \(X\). The goal is to show that if \(\|(\lambda,x)-(\psi,x_0)\| &lt; \delta.\) Then \(\|\lambda x - \psi x_0 \| &lt; \epsilon \). Usually whenever I try to work out these sorts of inequalities, I never really see it until I see a cheesed out answer. So here is the cheesed out answer. Consider 
</p>

<p>
\(\begin{equation} \begin{split}    \| \lambda x - \psi x_0 \| &amp;= \|\lambda x -\lambda x_0 + \lambda x_0 - \psi x_0\| \\ &amp;\leq \| \lambda x -\lambda x_0 \| + \| \lambda x_0 - \psi x_0 \| \\ &amp;= |\lambda| \|x-x_0\|+ |\lambda - \psi| \|x_0\| \end{split} \end{equation}\). 
</p>

<p>
What should one do in this situation? Why simply set \(\delta = \textrm{min} (1, \frac{\epsilon}{3\|x\|}, \frac{\epsilon}{3|\lambda|}, \frac{\epsilon}{3} ) \) Then we know that \(|\lambda - \psi| &lt; 1\). So then 
</p>

<p>
\( \begin{equation} \begin{split} |\lambda| \|x-x_0\|+ |\lambda - \psi| \|x_0\| &amp; \leq |\lambda - \psi| \|x\| + |\psi| \|x-x_0\| + |\lambda - \psi | \|x-x_0\| \\ &amp;&lt; \frac{\epsilon}{3} + \frac{\epsilon}{3} + \frac{\epsilon}{3} \\ &amp;&lt; \epsilon \end{split} \end{equation}\)
</p>

<p>
Thus, multiplication is continuous. 
</p>

<p>
To show that the norm \(\| \bullet \| : X \rightarrow [0,\infty)\) is continuous, we must first show that \(\| x + y \| \leq \|x\| + \|y\|\). Observe that: 
</p>

<p>
\( \|x\| = \|x-y+y\| \leq \|x-y\| + \|y\| \). Implying that \(\|x\| -\|y\| \leq \|x-y\|\). This is the reverse triangle inequality. 
</p>

<p>
Now to show continuity: Let x,y be elements of \(X\) and let \(\delta = \|x-y\| \), then \(| \|x\| - \|y\| | \leq \|x-y\| &lt; \epsilon \), then \(\|x-y\| &lt; \epsilon\) and we see that norm is continuous. 
</p>

<p>
Exercise 4: If \(X,Y\) are normed vector spaces, the map \((T,x) \rightarrow Tx \) is continuous from  \(L(X,Y) \times X \) to \(Y\). (If \(T_n \rightarrow T\) and \(x_n \rightarrow x\) then \(T_n x_n \rightarrow Tx\))
</p>

<p>
Proof:
To prove continuity of the operation, we must show that \(\|T_nx_n - Tx\| \rightarrow 0\). Since \(x_n\), it is bounded. So there exists some \(C&gt;0\) such that \(\|x_n\| \leq C , \forall n \in \mathbb{N}\). 
</p>

<p>
Then we have that 
\(\begin{equation} \begin{split}  \|T_nx_n-Tx\|  &amp; =  \|T_nx_n-Tx_n +Tx_n -Tx\| \\  &amp;= \|T_nxn_n - Tx_n\| + \|Tx_n -Tx_\| \\  &amp;= \|x_n\| \|T_n-T\|  + \|T\| \|x_n-x\| \\  &amp; \leq C \|T_n-T\| + \|T\| \|x_n -x\| \rightarrow 0,  \textrm{as } n \rightarrow \infty \end{split}\end{equation} \) 
</p>

<p>
Thus, we see that the map is continuous.
</p>

<p>
Exercise 7: Let \(X\) be a Banach space.
</p>

<ol>
<li>
If \(T \in L(X,X)\) and \(\|I-T\| &lt; 1\), where \(I\) is the identity operator, then \(T\) is invertible; in fact, the series \(\Sigma _0 ^\infty (I-T)^n \) converges in \(L(X,X)\) to \(T^{-1}\).

<li>
If \(T\in L(X,X)\) is invertible and \(\|S-T\| &lt; \|T^{-1}\|^{-1} \), then \(S\) is invertible. Thus the set of invertible operators is open in \(L(X,X)\).

</ol>
<p>
Proof: 
</p>

<p>
(1) First we observe that \(\|(I-T)^n \| \leq \| I -T\| ^n\). Since we know from our hypothesis that \(\|I-T\| &lt; 1\), we can conclude that \(\Sigma_{n=0}^\infty \|(I-T)^n\| \leq \Sigma_{n=0}^\infty \|I-T\|^n\) is absolutely convergent as \(n\rightarrow \infty\). Thus \(L(X,X)\) is a Banach space and this series converges to some \(K \in L(X,X)\). Then we can see that, via induction, that:
\(\begin{split} KT &amp;=(I +(I-T)+ ... + (I-T)^{n-1})T \\ &amp;=  I - (I-T)^n \\ &amp;= T(I+(I-T)+...+ (I-T)^{n-1}) = TK \end{split}\)
</p>

<p>
So then we see that as \(n \rightarrow \infty\) we see that \(KT\) simply becomes the identity operator. Thus proving invertability of \(T\).
Observe that \( \begin{equation}\begin{split} \|I-T^{-1}S\|=\|T^{-1}S - I\| &amp;= \|T^{-1}S - T^{-1}T \| \\  &amp;\leq \|T^{-1}\| \|S-T\| \\ &amp;&lt; \|T^{-1}\| \|T^{-1}\|^{-1} = 1 \end{split}\end{equation}\). 
</p>

<p>
The last inequality comes from our given.
</p>

<p>
(2) From part a. We can conclude that \(T^{-1}S\) is invertible and has an operator \(K \in L(X,X)\) such that \(KT^{-1}S = T^{-1}SK = I\). Then we can see that \(KT^{-1}\) is an inverse of \(S\). So every element of a \(\frac{1}{\|T^{-1}\|}-\textrm{ball }\) around \(T\) is invertible, and thus the set of invertible operators is open in \(L(X,X)\).  
</p>

<p>
Exercise 9: Let \(C^k([0,1])\) be the space of functions on \([0,1]\) possesing continuous derivatives up to order \(k\) on \([0,1]\), inclduing one sided derivatives at the endpoints.
</p>

<ol>
<li>
If \(f \in C([0,1])\), then \(f\in C^k([0,1])\) iff \(f\) is \(k\) times continuously differentiable on \((0,1)\) and \(lim_{x \searrow 0} f^{(j)}(x)\) and \(lim_{x \nearrow 1} f^{(j)}(x)\) exist for \(j \leq k\). 

<li>
\(\| f\| = \Sigma_0^k \|f^{(j)} \|_u \) is a norm on \(C^k([0,1])\) that makes it into a Banach space. 

</ol>
   
<p>
Proof: 
</p>

<p>
(1) The if direction is trivial. The definition for \(f\) to be an element of \(C^k([0,1])\) automatically satisfies the conditions on the \((0,1)\) and at the end points. Working backwards: If \(f\) is \(k\) times continuously differentiable in \((0,1)\) and \(lim_{x \searrow 0} f^{(j)}(x)\), \(lim_{x \nearrow 1} f^{(j)}(x)\) exist for \(j \leq k\). The mean value theorem tells us that for every \(c\in(0,1)\) there exists \(d \in (0,z)\) such that: \(\frac{f^{(j-1)}(x) - f^{(j-1)} (0)} {x} = f^{(j)} (c) \) Taking the limit \(x \searrow 0\), we get that \(f^{(j)} (0) = lim _{c \searrow 0} f^{(j)} (c) \).  This can be done similarly for \(x \nearrow 1\). Then, since we have that \(f\) is continuously differentiable at every point, we conclude \(f\in C^k([0,1])\)
</p>

<p>
(2) First we show that \( \| f\| = \Sigma_0^k \|f^{(j)} \|_u \) is a norm on \(C^k([0,1])\) Obviously, \(\| f\| \geq 0 \) for all \(f\in C^k([0,1])\). If \(f\in C^k([0,1])\) is nonzero, then \(\|f^{(0)}\|_u &gt; 0\) and so \(\|f\|&gt;0\). Now, let \(f,g \in C^k([0,1])\) and \(\lambda \in \mathbb{R}\). Then: \(  \|\lambda f \| = \Sigma_{j=0}^k \|\lambda f^{(j)} \|_u   = \Sigma_{j=0}^k |\lambda | \|f^{(j)} \|_u \) and \(\|f+g\| = \Sigma _{j=0} ^k \|f^{(j)} + g^{(j)} \|_u \leq \Sigma_{j=0}^k \|f^{(j)}\|_u + \Sigma_{j=0}^k \|g^{(j)}\|_u = \|f+\|g\|\)
</p>

<p>
Thus, we have shown this is a norm. Now we turn to show this is a Banach space.
</p>

<p>
Proceeding by induction, we consider the base case with \(C^0([0,1])\) and the norm \(\| f\|_u = \textrm{sup}_{[0,1]} |f|\). Let \({f_n}\) be a Cauchy sequence in \(C^0([0,1])\). Then:
</p>

<p>
\(\begin{split} \|f-f_n\|_u &amp; = \textrm{sup}_{[0,1]}|f(x)-f_n(x)| \\ &amp;= \textrm{sup}_{[0,1]} \textrm{lim}_{m \rightarrow \infty} |f_n(x)-f_m(x) | \\ &amp; \leq \textrm{lim  inf}_{m \rightarrow \infty} \textrm{sup}_{[0,1]} | f_n(x)-f_m(x) | \\ &amp;\rightarrow 0, \textrm{as  } n \rightarrow \infty  \end{split} \)
</p>

<p>
Now let us suppose that this holds for \(j \leq k\), we wish to show that this holds for \(j=k+1\). Let \({f_n}\) be a Cauchy sequence in  \(C^{k+1}([0,1])\). Then:
</p>

<p>
\(\Sigma_0^k \|f_n^{(j)}-f_m^{j}\|_u &lt; \Sigma_0^{k+1} \|f_n^{(j)}-f_m^{j}\|_u = \|f_n -f_m\| \)
</p>

<p>
So then this is also a Cauchy sequence in \(C^k([0,1])\) and converges to some \(f \in C^k([0,1])\). So then our space is complete.
</p>

<p>
Exercise 10: Let \(L^1_k([0,1])\) be the space of all \(f \in C^{k-1}([0,1])\) such that \(f^{(k-1)}\) is absolutely continuous on \([0,1]\). Then \(\|f\| = \Sigma_0^k \int _0 ^1 | f^{(j)}(x)| dx\) is a norm on \(L^1_k([0,1])\) that makes it into a Banach space.
</p>

<p>
Proof: First we check that this is norm. First and foremost, this is obviously nonnegative. Scalars can be removed safely as well. So we really just need to show that this satisfies the triangle inequality. That is, if \(f,g \in L^1_k([0,1])\), then \(\begin{split} \|x+y\|= \Sigma_0^k \int _0 ^1 | f^{(j)}(x) + g^{(j)}(x)| dx  &amp; \leq  \Sigma_0^k(\int_0^1|f^{(j)}(x)|dx + \int_0^1|g^{(j)}(x)|dx) \\ &amp;= \Sigma_0^k \int _0 ^1 | f^{(j)}(x)| dx + \Sigma_0^k \int _0 ^1 | g^{(j)}(x)| dx \\ &amp;= \|x\| + \|y\|  \end{split}\)
</p>

<p>
Thus, this is in fact a norm. Now we need to show this is a Banach space. 
</p>

<p>
A small adaptation of part b from the previous exercise will prove this is a Banach space. (incomplete)
</p>

<p>
Exercise 11: Hoelder continuous.
</p>

<p>
Proof: I'll only show triangle inequality, others are trivial.
</p>

<p>
Suppose we have \(f,g \in \Lambda_\alpha ([0,1])\). Then:
</p>

<p>
\(\begin{split} \|f+g\|_{\Lambda_\alpha} &amp;= |f(0) + g(0) | + \textrm{sup}_{x,y\in[0,1], x\neq y} \frac{|f+g(x)-f+g(y)|}{|x-y|^\alpha} \\ &amp; \leq |f(0)| +|g(0)| +  \textrm{sup}_{x,y\in[0,1], x\neq y} \frac{|f(x)-f(y)|}{|x-y|^\alpha} +  \textrm{sup}_{x,y\in[0,1], x\neq y} \frac{|g(x)-g(y)|}{|x-y|^\alpha} = \|f\|_{\Lambda_\alpha} + \|g\|_{\Lambda_\alpha} \end{split} \)
</p>

<p>
Thus, \(\| \bullet \|_{\Lambda_\alpha}\) is a norm. 
</p>

<p>
Now we turn to show that \(\Lambda_\alpha ([0,1])\) into a Banach space. 
</p>

<p>
Exercise 12: Let \(X\) be a normed vector space and \(M\) a proper closed subspace of \(X\). 
</p>
<ol>
<li>
\(\| x + M \| = \textrm{inf} {\|x+y\| : y\in M}\) is a norm on \(X\setminus M\).

<li>
For any \(\epsilon &gt; 0 \) there exists \(x\in X\) such that \(\| x\| = 1\) and \(\|x + M \| \geq 1 - \epsilon\).

<li>
The projection map \(\pi(x) = x+ M \) from \(X \) to \(X \setminus M\) has norm 1.

<li>
If \(X\) is complete, so is \(X\setminus M\)

<li>
The topology defined by the quotient norm is the quotient topology as in Exercise 28 of 4.2

</ol>
<p>
Proof: 
</p>
<ol>
<li>
Clearly \(0+M = M\), implying that \(0 \in M\) and so \(\| 0 + M \| = \textrm{inf}\{\|0+y \| : y \in M\} = 0\). Next, we observe that

</ol>
<p>
\( \begin{split} \| \lambda x + M \| &amp;= \textrm{inf}_{y\in M} \| \lambda x +y \| \\ &amp;= | \lambda | \textrm{inf}_{y\in M} \| x + \frac{y}{a} \| \\ &amp;= |\lambda | \textrm{inf}_{ y \in M} \|x + y\| \\ &amp;= | \lambda | \|x+ M\| \end{split}\)
</p>

<p>
Also:
</p>

<p>
\( \begin {split} \|x+y+M\| &amp;= \textrm{inf}_{z\in M} \|x+y+z\|  \\  &amp; \leq \textrm{inf}_{z\in M} \|x + \frac{z}{2} \| + \textrm{inf}_{z \in M } \| y + \frac{z}{2} \|   \\  &amp; = \textrm{inf}_{z \in M} \|x + z\| + \textrm{inf}_{z \in M} \| y + z\|  \\ &amp; = \|x + M \| + \|y + M \| \end{split}\)
</p>

<p>
So \(\| x + M \| \) is a norm on \(X \setminus M\).
</p>

<ol>
<li>
Suppose that for \(x \in X \setminus M\) we have that \(\|x+M\|  \leq \frac{\|x + M}{1-\epsilon}\). Then that means we have a \(y\in M\) such that \(\|x+y\| \leq \frac{\|x + M}{1-\epsilon}=\frac{(x+y)+M}{1-\epsilon}\). After switching fractions, we see that \(1-\epsilon \leq \| \frac{x+y}{\|x+y\|}+M\|= \| 1 + M \| \). 

</ol>
   
<ol>
<li>
Observe that the projection map has norm \(\| \pi \| = \textrm{sup} \{ \frac{\| \pi x \|}{\|x\|} : x \neq 0 \} \leq 1\). However, the previous part tells us that\(\| \pi = \textrm{sup} _P{\|x\|=1} \|x+M\| \geq 1-\epsilon\| \). Since \(\epsilon\) is arbitrary, we see that \(\| \pi\| = 1 \).

<li>
Suppose that \(X\) is complete and that \(\sum_{n=1}^{\infty}(x_n + M)\) is an absolutely convergent series in \(X \setminus M \). Theorem 5.1 lets us find a \(y\in M\) such that the \(\sum_{n=1}{\infty} \|x_n + y\| &lt; \sum_{n=1}{\infty}(\|x_n + M \| + \frac{1}{2^n}) &lt; \infty \). 

</ol>
<p>
So then the sequence \(\{x_n +y \}_{n=1}^{\infty}\) is a sequence that is absolutely convergent as a series. From completeness of \(X\), this converges to an element of \(X\), say \(x\). As a series in \( X\setminus M\), this absolutely converges to \( x +M \). 
</p>
   
<ol>
<li>
To be continued... 

</ol>
   
<p>
Exericse 15:Suppose that \(X\) and \(Y\) are normed vector spaces and \(T\in L(X,Y).\)l Let \(N(T)= \{x\in X : Tx=0 \} \) 
</p>
<ol>
<li>
\(N(T)\) is a closed subspace of \(X\). 

<li>
There is a unique \( S \in L(X \setminus N(T), Y)\) such that \(T = S \circ \pi\) where \(\pi : X \rightarrow X \setminus N(T)\) is the projection \(\pi (x)= x + N(T)\) and \(\|S\| = \|T\| \) 

</ol>
   
<p>
Proof: 
</p>
<ol>
<li>
Since \(T\) is an element of \(L(X,Y)\), it is continuous. Note also, that \(\{0\}\) is a closed set in \(Y\). So then, \(N(T) = T^{-1}(\{0\})\) is a closed set in X.

<li>
Let \( S: X\setminus N(T) \rightarrow Y\) be the map such that \(S(x + N(T)) = Tx\). This map is well defined by the fact that if \(x+N(T)=y+N(T)\), then \((x-y) \ in N(T)\). So then \(S(x+N(T)) = Tx = Tx +Ty - Ty = Ty + T(x-y) = T(y) = S(y+N(T))\). Further, this map is also linear since:

</ol>
<p>
\(S((\lambda x + \psi y) +N(T)) = T(\lambda x + \psi y) =\lambda T x + \psi T y = \lambda S(x+N(T)) + \psi S(y+N(T))\)
</p>

<p>
Further, this map is also bounded below since \(\|S(x+N(T))\| = \|Tx\| \leq \|x\|\)
</p>

<p>
So we can conclude that \(S \in L(X\setminus N(T), Y)\). 
</p>

<p>
Then we notice that \(\begin{split} \|T\| &amp;= \textrm{sup}_{x \neq 0} \frac{\|Tx\|}{\|x\|} = \textrm{sup}_{x \notin N(T)} \frac{\|S(\pi(x))\|}{\|x\|} \\ &amp;= \textrm{sup}_{x\notin N(T)} \frac{\| S(\pi(x)) \|}{\| \pi(x) \|} \frac{\| \pi(x) \| }{\|x\|} = \textrm{sup}_{x \notin N(T)} \frac{\| S (\pi (x))\|} {\pi(x)} \textrm{sup}_{x \notin N(T)} \frac{\| \pi(x) \| } {\|x\|} = \|S\| \| \pi \| = \|S\| \end{split} \)
</p>

<p>
Exercise 17: A linear functional \(f\) on a normed vector space \(X\) is bounded iff \(f^{-1} (\{0 \}) \) is closed. 
</p>

<p>
Proof: In the forwards direction: If a linear functional is bouded, then it is continuous. So then the preimage of a closed set is closed. Thus, \(f^{-1}( \{0 \})\) is closed.
</p>

<p>
In the reverse direction: Let \(K = f^{-1}(\{0 \})\) be a closed subset of \(X\). Using the previous exercise, we can find an \(x \in X\) such that it has norm 1 and \(\| x+ K ) \| \geq \frac{1}{2} \). Further, for any \(x \in X\), we have \(y \in K\) such that
</p>

<p>
\(|f(\lambda x +y)| = |\lambda| |f(x)| \leq 2 |\lambda| \frac{1}{2} |f(x)| \leq 2 |\lambda| \|x+K\| |f(x)| \leq 2 |\lambda | \|x+ \frac{y}{\lambda}\| |f(x)| = 2|f(x)| \|\lambda x +y\|\). So then \(f\) is bounded.
</p>

<p>
Exercise 18: Let \(X\) be a normed vector space. 
</p>
<ol>
<li>
If \(M\) is a closed subspace and \(x \in X \setminus M\) then \(M + \mathbb{C} x\) is closed

<li>
Every finite dimensional subspace of \(X\) is closed. 

</ol>
   
<p>
Proof: 
</p>
<ol>
<li>
Take a sequence \(\{x_n +\lambda_n x \} \subset M + \mathbb{C} \) that converges to some \(y \in X\). Since \(f\) is is linear and continuous, 0 everywhere in \(M\). We get that 

</ol>
   
<p>
   \( f(y)= \textrm{lim}_n f(x_n + \lambda_n x)= \textrm{lim}_n \lambda_n f(x)  \) 
</p>
   
<p>
Implying that \(\textrm{lim}_n \lambda_n = \frac{f(y)}{f(x)} = \lambda\)
</p>

<p>
Giving us that \(x_n=y -\lambda_n x \rightarrow y-\lambda = x_o \in M\).So then \(y= x_0 + \lambda x \in M + \mathbb{C} x\). So we're done 
</p>

<ol>
<li>
Every finite dimensinoal subspace of \(X\) is of some \(M +\mathbb{C}x\) If we start \(M = \{0 \}\), we can build up any finite dimensional space by inducting on \(M_1=M+\mathbb{C}x_1\) where \(x_1\) is the new element we append to our finite dimensinoal space.

</ol>
<p>
Exercise 19: Let \(X\) be an infinite dimensional normed vector space. 
</p>
<ol>
<li>
There is a seqeunce \(\{x_j \}\) in X such that \(\| x_j\| =1 \)for all \(j\) and \(\|x_j - x_k\| \geq \frac{1}{2}\) for \(j \neq k\).

<li>
\(X\) is not locally compact.

</ol>
<p>
Proof: 
Start with an \(x \in X\) such that it has norm 1. Then \(\mathbb{C}x\) is a closed subspace of \(X\) from what we showed in the previous exercise. Using 12b, set \(\epsilon = \frac{1}{2}\), so then we can find a new element, \(x_0 \in X\) such that it has norm 1 and also \(\|x_0 -x\| \geq \frac{1}{2}\). Proceeding inductively by finding an element \(x_2 \in \mathbb{C}x \oplus \mathbb{C}x_1\) 
</p>

<p>
For the next part, we can use what we just shown to find a sequence that has no convergent subsequence. Thus, no compact neighborhood, so not locally compact.
</p>

<p>
Exercise 27: There exists meager subsets of \(\mathbb{R}\) that have complement with lebesegue measure 0.
</p>

<p>
Proof: Let \(X\) be a topological space in \(\mathbb{R}\) and \(E \subset X\) be a meager set and let \(\{x_n \}\) be an enumeration for the rationals. Then the set \(E_n = \cup _{k=1}^{\infty} (x_k - \frac{1}{2^{k-1}n}, x_k + \frac{1}{2^{k-1}n})\). Then the set \(E= \cap_1^\infty E_n\) has measure 0 since \(m(E_n)\leq \sum_{k=1}^{\infty} \frac{1}{2^k n} = \frac{1}{n} \). Since \(E_n\) is open, then \(E_n^c\) is closed. Further, \(E_n\) is dense in \(\mathbb{R}\) since each \(E_n\) has the rationals inside it. Thus, \(E_n^c\) is nowhere dense, and as such, \(E^c= \cup_{n=1}^{\infty} E_n^c\) is meager. 
</p>

<p>
Exercise 30: Let \(Y = C([0,1])\) and \(X=C^1([0,1])\), both equipped with with the uniform norm.
</p>
<ol>
<li>
\(X\) is not complete 

<li>
The map \((d/dx): X \rightarrow Y\) is closed but not bounded.

</ol>
<p>
Proof: 
First we make the obersvation that \(X \subset Y\), proper, since \(f(x) = \sqrt{x} \in Y \setminus X \). Using exercise 9n, we have that 
</p>

<p>
\(f_n(x) - f_n(0) = \int_0 ^x \frac{d}{dt} f_n(t) dt\)
</p>

<p>
However, we get that these spaces are uniformly convergent. So then we have that pointwise: \(f_n(x) - f_n(0) \rightarrow f(x) - f(0) \) converges. 
</p>

<p>
Then we see that \(\int_0 ^x \frac{d}{dt} f_n(t) dt \rightarrow \int_0 ^x g(t) dt\)
</p>

<p>
And that \(g=(d/dt)f\) from FTC, thus \((d/dx)\) is closed.
</p>

<p>
To see unbounded, consider \(f_n(x) = sin(nx)\), this has norm 1 for all \(n \in N\) but taking the first derivative, we see that the norm is \(\|n cos(nx)\| = n\), which can be as large as we desire. So, unbounded. 
</p>

<p>
Exercise 38: Let \(X\) and \(Y\) be Banach spaces, and let \(\{T_n \}\) be a sequence in \(L(X,Y)\) such that \(\textrm{lim}T_n x \) exists for every \(x \in X\). Let \(Tx = lim T_n x\), then \(T \in L(X,Y)\)
</p>

<p>
Proof: First note that \(T\) is linear. 
</p>

<p>
\( T(x+\lambda y) = \textrm{lim}_n T_n(x+\lambda y) = \textrm{lim}_n T_nx + \lambda \textrm{lim}_n T_n y = Tx + \lambda Ty\)
</p>

<p>
From the uniform boundedness principle, we can conclude that \(\textrm{sup}_n \|T_n\| &lt; \infty\) for every \(x \in X\). Thus, \(T\) is bounded. 
</p>

<p>
Exercise 45: 
</p>

<p>
Exercise 48: Suppose that \(X\) is a Banach space.
</p>
<ol>
<li>
Show that the norm-closed unit ball \(B = \{x \in X : \|x\| \leq 1 \} \) is also weakly closed.

<li>
If \(E \subset X\) is bounded, so is its weak closure.

<li>
If \(F^* \subset X\) is bounded, so is its weak* closure.

<li>
Every weak* Cauchy sequence in \(X^*\) converges.

</ol>
<p>
Proof: 
</p>
<ol>
<li>
Let \(\braket{x_n}\) be a net in \(B\) that converges weakly to \(x\in X\). Applying theorem 5.8, we see that \(\|x_0\| = \| \tilde{x_0}\|\) for all \(x_0 \in X\). We conclude that for every \(x_n\) in our net, \(\tilde{x_n} \in B^{**} = \{ \x' \in X : \|x'\| = 1 \}\). It becomes appartent then that our net \(\braket{\tilde{x_n}}\) converges to \(\tilde{x}\) in the weak* topology on \(X^{**}\). Because this is hausdorff, we see that compact sets are closed and by Alaoglu, \(\tilde{x} \in B^{**}\). Then \(\|x\| = \|\tilde{x}\| \leq 1 \) and \(x \in B\). So \(B\) is weakly closed.

<li>
If \(E \subseteq X\) is bounded, then we have a constant \(\lambda &gt; 0\) such that \(\| x\| \leq \lambda\) for all \(x \in E\). Clearly then, \(\| \frac{x}{\lambda} \| \leq 1 \)for all \(x\in E\). In \(E\), take a weakly convergent net \(\braket{x_n}\) to \(x \in X\). Continuity of multiplication dictates that our net will converge weakly to \(\frac{x}{\lambda}\), the previous part indicates that it is also an element of \(B\). Thus, the weak closure of \(E\) is bounded.

<li>
If \(F \subseteq X^*\) is bounded, then there exists a \( \lambda &gt; 0\) such that \(\|f\| \leq \lambda \) for all \(f \in X^*\). Take a net in \(F\) that converges to \(f\in X^*\) in the weak* topology. Continuity of scalars assures a convergence of our net to \(\frac{f}{\lambda}\). We can apply Alaoglu's theorem on the net, which converges in \(B^*\). Thus proving that the weak* closure of \(F\) is bounded.

<li>
Take a cauchy sequence in \(X^*\) with respect to the weak* topology. Then for all \(x \in X\), we have that \(|f_n(x) -f_m(x)| \rightarrow 0\) as \(n,m \rightarrow \infty\). Completeness of \(\mathbb{C}\) tells us that this limit exists and a previous exercise lets us see that the limit converges in the weak* topology and we're done.

</ol>
<p>
Exercise 56:
</p>

<p>
If \(x \in E \) and \(y \in E^\perp\), then \(x \perp y \) and so \(x \in (E^\perp)^\perp\). Clearly, \((E^\perp)^\perp\) is closed in \(H\). If there was another closed subspace of \(H\) containing \(E\), call it \(M\), then clearly \(M^\perp \subseteq E^\perp\). Then we can extend this idea to see that \((E^\perp)^\perp \subseteq (M^\perp)^\perp\). Taking an element \( m \in (M^\perp)^\perp\), we can express it as a sum of elements, \(x+y\) from \(M\) and \((M ^\perp)\) respectively. But then notice that since \(m \perp y\). We get that \(0= \braket{m,y} = \braket{x,y} + \braket{y,y} = \|y\|^2.\) So then, \(y = 0 \) and so \(m \in M\). Thus proving that \((E^\perp)^\perp\) is the smallest closed subspsace containing \(E\). 
</p>

<p>
Exercise 60:
</p>

<p>
Vague idea: What we want to see is the each \(L^2 (E_n, \mu)\) is closed and so then if we consider the sequence \(f_n = f \chi_{E_n}\), then f is clearly the sum of all the \(f_n\)'s and each \(f_n \in L^2(E_n, \mu)\). Convergence of the \(f_n\) follows from the dominated convergence theorem. 
</p>

<p>
For the next part, fix a countable dense subset of \(L^2(E_n, \mu)\), then we could make a countable union and find some some sequence that converges to \(f\). 
</p>

<p>
Exercise 61:
</p>

  </div>

  <hr>
  <script>
    document.write(
      "This page was powered by Vimwiki and was last modified on: " +
      document.lastModified
    );
  </script>
  <hr>
  <center>&copy; Mauricio Montes, <span id="copy-year"></span>,
    myfirstname.mylast@auburn.edu
  </center>
  <script>
    document.getElementById('copy-year').textContent = new Date().getFullYear();
  </script>
</body>
</html>

